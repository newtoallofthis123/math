{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test', 'train']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir = \"dogs_cats\"\n",
    "train_dir = os.path.join(dataset_dir, \"train\")\n",
    "test_dir = os.path.join(dataset_dir, \"test\")\n",
    "\n",
    "os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "# Only rescale pixel values for validation data\n",
    "validation_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 557 images belonging to 2 classes.\n",
      "Found 140 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(150, 150, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 15s 844ms/step - loss: 0.6929 - accuracy: 0.4883 - val_loss: 0.6928 - val_accuracy: 0.5500\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 12s 673ms/step - loss: 0.6939 - accuracy: 0.5171 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 12s 655ms/step - loss: 0.6912 - accuracy: 0.5027 - val_loss: 0.6924 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 11s 635ms/step - loss: 0.6885 - accuracy: 0.5332 - val_loss: 0.6870 - val_accuracy: 0.5286\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 11s 589ms/step - loss: 0.6758 - accuracy: 0.6014 - val_loss: 0.6864 - val_accuracy: 0.5286\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 11s 585ms/step - loss: 0.6617 - accuracy: 0.5889 - val_loss: 0.6736 - val_accuracy: 0.5929\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 11s 590ms/step - loss: 0.6393 - accuracy: 0.6409 - val_loss: 0.6669 - val_accuracy: 0.6000\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 11s 585ms/step - loss: 0.6227 - accuracy: 0.6553 - val_loss: 0.6776 - val_accuracy: 0.6286\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 10s 578ms/step - loss: 0.5920 - accuracy: 0.6966 - val_loss: 0.6688 - val_accuracy: 0.6286\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 11s 593ms/step - loss: 0.5630 - accuracy: 0.6984 - val_loss: 0.6900 - val_accuracy: 0.6786\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 11s 591ms/step - loss: 0.5467 - accuracy: 0.7397 - val_loss: 0.7141 - val_accuracy: 0.6643\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 11s 590ms/step - loss: 0.5489 - accuracy: 0.7361 - val_loss: 0.7449 - val_accuracy: 0.6571\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 10s 563ms/step - loss: 0.5477 - accuracy: 0.7181 - val_loss: 0.6604 - val_accuracy: 0.6643\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 10s 557ms/step - loss: 0.5103 - accuracy: 0.7433 - val_loss: 0.7907 - val_accuracy: 0.6357\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 10s 561ms/step - loss: 0.4690 - accuracy: 0.7666 - val_loss: 0.7644 - val_accuracy: 0.6643\n",
      "Epoch 16/30\n",
      "18/18 [==============================] - 11s 587ms/step - loss: 0.4649 - accuracy: 0.7792 - val_loss: 0.7208 - val_accuracy: 0.6357\n",
      "Epoch 17/30\n",
      "18/18 [==============================] - 14s 756ms/step - loss: 0.4426 - accuracy: 0.7882 - val_loss: 0.6653 - val_accuracy: 0.6714\n",
      "Epoch 18/30\n",
      "18/18 [==============================] - 16s 896ms/step - loss: 0.4700 - accuracy: 0.7648 - val_loss: 0.6587 - val_accuracy: 0.6500\n",
      "Epoch 19/30\n",
      "18/18 [==============================] - 14s 792ms/step - loss: 0.4186 - accuracy: 0.8079 - val_loss: 0.7902 - val_accuracy: 0.6071\n",
      "Epoch 20/30\n",
      "18/18 [==============================] - 14s 759ms/step - loss: 0.4670 - accuracy: 0.7594 - val_loss: 0.7461 - val_accuracy: 0.6714\n",
      "Epoch 21/30\n",
      "18/18 [==============================] - 12s 664ms/step - loss: 0.3910 - accuracy: 0.8259 - val_loss: 0.6835 - val_accuracy: 0.6714\n",
      "Epoch 22/30\n",
      "18/18 [==============================] - 12s 660ms/step - loss: 0.3464 - accuracy: 0.8510 - val_loss: 0.7685 - val_accuracy: 0.6857\n",
      "Epoch 23/30\n",
      "18/18 [==============================] - 12s 671ms/step - loss: 0.3848 - accuracy: 0.8348 - val_loss: 0.7590 - val_accuracy: 0.6929\n",
      "Epoch 24/30\n",
      "18/18 [==============================] - 12s 664ms/step - loss: 0.3640 - accuracy: 0.8241 - val_loss: 0.7333 - val_accuracy: 0.7214\n",
      "Epoch 25/30\n",
      "18/18 [==============================] - 12s 670ms/step - loss: 0.3113 - accuracy: 0.8654 - val_loss: 0.7622 - val_accuracy: 0.7214\n",
      "Epoch 26/30\n",
      "18/18 [==============================] - 12s 679ms/step - loss: 0.3155 - accuracy: 0.8510 - val_loss: 0.7375 - val_accuracy: 0.7071\n",
      "Epoch 27/30\n",
      "18/18 [==============================] - 12s 676ms/step - loss: 0.3232 - accuracy: 0.8654 - val_loss: 0.8409 - val_accuracy: 0.7214\n",
      "Epoch 28/30\n",
      "18/18 [==============================] - 11s 580ms/step - loss: 0.2674 - accuracy: 0.9013 - val_loss: 0.7150 - val_accuracy: 0.6857\n",
      "Epoch 29/30\n",
      "18/18 [==============================] - 11s 580ms/step - loss: 0.2445 - accuracy: 0.8995 - val_loss: 0.9404 - val_accuracy: 0.7071\n",
      "Epoch 30/30\n",
      "18/18 [==============================] - 11s 632ms/step - loss: 0.2801 - accuracy: 0.8743 - val_loss: 0.7964 - val_accuracy: 0.6929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x188159c5840>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 - 1s - loss: 0.7964 - accuracy: 0.6929 - 929ms/epoch - 186ms/step\n",
      "Test accuracy: 0.6928571462631226\n",
      "Test loss: 0.7963787913322449\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "\n",
    "test_loss, test_acc = model.evaluate(validation_generator, verbose=2)\n",
    "\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "print(\"Test loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "# Dog.jpg\n",
    "\n",
    "img = keras.preprocessing.image.load_img(\n",
    "    \"dog.jpg\",\n",
    "    target_size=(150, 150)\n",
    ")\n",
    "\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joshi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "\n",
    "model.save(\"dogs_cats.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n",
      "This image most likely belongs to dog\n"
     ]
    }
   ],
   "source": [
    "# Load and test the model\n",
    "\n",
    "model = keras.models.load_model(\"dogs_cats.h5\")\n",
    "\n",
    "img = keras.preprocessing.image.load_img(\n",
    "    \"dog.jpg\",\n",
    "    target_size=(150, 150)\n",
    ")\n",
    "\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "print(\"This image most likely belongs to {}\"\n",
    "    .format(\"dog\" if predictions[0] == 1 else \"cat\",)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
